{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UItUTytqvyN3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5kRQDLTv0wh",
        "outputId": "268be821-a3e7-42b9-cc21-2776eb6bee19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9BfsbhZw7rY",
        "outputId": "0b850539-44c8-48d3-cdfe-662d7c8e8adc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting reformer_pytorch\n",
            "  Downloading reformer_pytorch-1.4.4-py3-none-any.whl (16 kB)\n",
            "Collecting product-key-memory\n",
            "  Downloading product_key_memory-0.1.10.tar.gz (3.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting axial-positional-embedding>=0.1.0\n",
            "  Downloading axial_positional_embedding-0.2.1.tar.gz (2.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from reformer_pytorch) (2.0.0+cu118)\n",
            "Collecting local-attention\n",
            "  Downloading local_attention-1.8.5-py3-none-any.whl (8.1 kB)\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (3.12.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (1.11.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->reformer_pytorch) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->reformer_pytorch) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->reformer_pytorch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->reformer_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: axial-positional-embedding, product-key-memory\n",
            "  Building wheel for axial-positional-embedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axial-positional-embedding: filename=axial_positional_embedding-0.2.1-py3-none-any.whl size=2901 sha256=0c223f675c7156cf525f64d9665df9f3cd0db3c00cd7ebf5eeba18916e788d70\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/cb/39/7ce7ff2d2fd37cfe1fe7b3a3c43cf410632b2ad3b3f3986d73\n",
            "  Building wheel for product-key-memory (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for product-key-memory: filename=product_key_memory-0.1.10-py3-none-any.whl size=3068 sha256=2b86fa0a5aff3649571176cef8bd1e6ef6c5ef81db662096d150fe59fc1cb75b\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/97/82/f94ef75772952e1eaec19864fc840620ec94d9ac7c9c0b6823\n",
            "Successfully built axial-positional-embedding product-key-memory\n",
            "Installing collected packages: einops, product-key-memory, local-attention, axial-positional-embedding, reformer_pytorch\n",
            "Successfully installed axial-positional-embedding-0.2.1 einops-0.6.1 local-attention-1.8.5 product-key-memory-0.1.10 reformer_pytorch-1.4.4\n"
          ]
        }
      ],
      "source": [
        "!pip install reformer_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeeK5RaOtrol",
        "outputId": "8cab16fd-4a1a-419d-d727-ccafb78ebf15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'pm_prediction'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 15 (delta 4), reused 13 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (15/15), 7.08 KiB | 1.77 MiB/s, done.\n",
            "Submodule 'Autoformer' (https://github.com/hjk1996/Autoformer.git) registered for path 'Autoformer'\n",
            "Cloning into '/content/pm_prediction/Autoformer'...\n",
            "remote: Enumerating objects: 330, done.        \n",
            "remote: Counting objects: 100% (157/157), done.        \n",
            "remote: Compressing objects: 100% (55/55), done.        \n",
            "remote: Total 330 (delta 118), reused 121 (delta 102), pack-reused 173        \n",
            "Receiving objects: 100% (330/330), 2.18 MiB | 27.27 MiB/s, done.\n",
            "Resolving deltas: 100% (193/193), done.\n",
            "Submodule path 'Autoformer': checked out '6c8364714f32a06d316fad86c0d7d15f386b450f'\n",
            "/content/pm_prediction\n"
          ]
        }
      ],
      "source": [
        "!git clone --recursive https://github.com/hjk1996/pm_prediction.git\n",
        "%cd pm_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY-usDcawRk6",
        "outputId": "875a73cf-359b-442a-eea8-8e58c7374d92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use CPU\n",
            ">>>>>>>start training : test_Autoformer_custom_ftMS_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 11972401\n",
            "val 1710277\n",
            "test 3420645\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/pm_prediction/autoformer_test.py\", line 137, in <module>\n",
            "    main()\n",
            "  File \"/content/pm_prediction/autoformer_test.py\", line 124, in main\n",
            "    exp.train(setting)\n",
            "  File \"/content/pm_prediction/Autoformer/exp/exp_main.py\", line 168, in train\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 487, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 200, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python autoformer_test.py --is_training 1 --model_id test --model Autoformer --data custom --root_path /content/drive/MyDrive/pollution --data_path autoformer_test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etTyqlIZw3ip"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}